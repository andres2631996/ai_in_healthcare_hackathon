{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"andres_training.ipynb","provenance":[],"authorship_tag":"ABX9TyN32/5Jz3PabSQf9yf1tPHQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxWkgqA93V64","executionInfo":{"status":"ok","timestamp":1620492797464,"user_tz":-120,"elapsed":547,"user":{"displayName":"Andres Martinez","photoUrl":"","userId":"15908124198162574990"}},"outputId":"fc1f8396-017e-4efa-bf76-4c0d27244b13"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"az46woNX3dzU","executionInfo":{"status":"ok","timestamp":1620491721669,"user_tz":-120,"elapsed":8879,"user":{"displayName":"Andres Martinez","photoUrl":"","userId":"15908124198162574990"}},"outputId":"92281e4f-cd05-4043-eacc-16bd67a57c6d"},"source":["pip install albumentations"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting albumentations\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/58/63fb1d742dc42d9ba2800ea741de1f2bc6bb05548d8724aa84794042eaf2/albumentations-0.5.2-py3-none-any.whl (72kB)\n","\r\u001b[K     |████▌                           | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 22.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 30kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 40kB 10.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 61kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n","Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.16.2)\n","Collecting imgaug>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n","\u001b[K     |████████████████████████████████| 952kB 10.7MB/s \n","\u001b[?25hCollecting opencv-python-headless>=4.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/84/72ec52fbac4775c2a5bf0ee5573c922a0cac35eb841907edf56493a5e313/opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2MB)\n","\u001b[K     |████████████████████████████████| 38.2MB 107kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.1.1)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.5.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations) (4.1.2.30)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations) (1.7.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.10.0)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.16.1->albumentations) (4.4.2)\n","Installing collected packages: imgaug, opencv-python-headless, albumentations\n","  Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed albumentations-0.5.2 imgaug-0.4.0 opencv-python-headless-4.5.2.52\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ISdyOmJO5OQK","executionInfo":{"status":"ok","timestamp":1620492805407,"user_tz":-120,"elapsed":743,"user":{"displayName":"Andres Martinez","photoUrl":"","userId":"15908124198162574990"}}},"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/AI_in_Healthcare_Hackaton/Scripts/Code_Andres/training_code\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"_y2lPoRR32m0","executionInfo":{"status":"ok","timestamp":1620492807718,"user_tz":-120,"elapsed":1536,"user":{"displayName":"Andres Martinez","photoUrl":"","userId":"15908124198162574990"}}},"source":["from dataLoader import Images,augmentation,preprocessing\n","from sklearn.model_selection import KFold\n","from model_vgg11_shortSkipPretrained import VAE\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader \n","import train\n","import itertools\n","import time"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KujIVIUj4VY3","executionInfo":{"status":"ok","timestamp":1620492809436,"user_tz":-120,"elapsed":425,"user":{"displayName":"Andres Martinez","photoUrl":"","userId":"15908124198162574990"}}},"source":["def getDataLoader(data,params):\n","    \"\"\"\n","    Extract data loader\n","    \n","    Params:\n","        - data : PyTorch dataset\n","            Dataset to be used for data-loading\n","        - params : dictionary\n","            Model and training parameters\n","            \n","    Outputs:\n","        - loader : PyTorch dataloader\n","            Extracted dataloader\n","    \n","    \"\"\"\n","    \n","    loader = DataLoader(data,\n","                        batch_size=params[\"batch_size\"],\n","                        num_workers = 0,\n","                        worker_init_fn = lambda id: np.random.seed(torch.initial_seed() // 2**32 + id),\n","                        shuffle=True,\n","                        pin_memory=True)\n","    \n","    return loader\n","\n","\n","\n","def splitTrainValData(orig_data,train_idx,val_idx):\n","    \"\"\"\n","    Split original dataset into training + validation datasets\n","    \n","    Params:\n","        - orig_data : dataset\n","            Original dataset\n","        - train_idx : np.ndarray\n","            Training indices for original dataset\n","        - val_idx : np.ndarray\n","            Validation indices for original dataset\n","            \n","    Outputs:\n","        - trainData : dataset\n","            Training dataset\n","        - valData : dataset\n","            Validation dataset\n","    \n","    \"\"\"\n","    \n","    trainData = Images()\n","    valData = Images()\n","    \n","    d = orig_data.dcms\n","    a = orig_data.ages\n","    c = orig_data.contrasts\n","    t = orig_data.tags\n","    tr = orig_data.trans\n","    \n","    trainData.__dcm = d[train_idx]\n","    trainData.__age = a[:,train_idx]\n","    trainData.__contrast = c[:,train_idx]\n","    trainData.__contrastTag = t[:,train_idx]\n","    trainData.__tran = tr\n","    \n","    valData.__dcm = d[val_idx]\n","    valData.__age = a[:,val_idx]\n","    valData.__contrast = c[:,val_idx]\n","    valData.__tag = t[:,val_idx]\n","    valData.__tran = None\n","    \n","    return trainData,valData"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"Het1aYiF5fnP","executionInfo":{"status":"error","timestamp":1620493410381,"user_tz":-120,"elapsed":556224,"user":{"displayName":"Andres Martinez","photoUrl":"","userId":"15908124198162574990"}},"outputId":"630f5036-a178-45fb-c298-403b3046c119"},"source":["# Global variables\n","    \n","init = time.time()\n","\n","path = \"/content/drive/MyDrive/AI_in_Healthcare_Hackaton/Scripts/images\"\n","\n","preprocessing_params = { \"resample\"        : True,\n","                         \"resolution\"      : 1.2,\n","                         \"output_dim\"      : 256,\n","                         \"resample_order\"  : 2,\n","                         \"equalize\"        : True,\n","                         \"clahe_win\"       : 2,\n","                         \"clahe_clip_size\" : 5,\n","                         \"normalize\"       : True}\n","\n","augmentation_params = { \"rot\"             : 60,\n","                        \"contrast\"        : 0.02, \n","                        \"bright\"          : 0.02,\n","                        \"sigma\"           : 2,\n","                        \"points\"          : 8,\n","                        \"resample_order\"  : 2}\n","\n","# Model parameters\n","model_params = {\"filters\"          : 32,\n","                \"layers\"           : 5,\n","                \"batch_norm\"       : True,\n","                \"batch_size\"       : 1,\n","                \"output_dim\"       : preprocessing_params[\"output_dim\"],\n","                \"latent_dims\"      : 4,\n","                \"use_gpu\"          : True,\n","                \"epochs\"           : 200,\n","                \"print_epochs\"     : 5,\n","                \"optimizer\"        : \"Adam\",\n","                \"lr\"               : 1e-4,\n","                \"weight_decay\"     : 1e-5,\n","                \"lr_scheduling\"    : \"step\",\n","                \"lr_gamma\"         : 0.1,\n","                \"step\"             : 15, \n","                \"plateau_mode\"     : \"min\", \n","                \"plateau_patience\" : 10,\n","                \"var_beta\"         : 1,\n","                \"loss_reduction\"   : \"mean\",\n","                \"metadata\" : False,\n","                \"K\" : 1} \n","\n","log = \"/content/drive/MyDrive/AI_in_Healthcare_Hackaton/Scripts/Code_Andres/training_code/results_saturday_noMetadata_v2/log_pretrainedVAE.txt\" # Insert some valid direction for TXT file\n","#log = r\"C:/Users/andre/Downloads/Full_dataset_hackathon/results/log_pretrainedVAE.txt\"\n","log_folder = os.path.dirname(log)\n","\n","aug = augmentation(augmentation_params) # Augmentation class\n","preproc = preprocessing(preprocessing_params) # Preprocessing class\n","\n","# General arguments for data loading\n","args = [os.path.join(path,\"overview.csv\"),\n","        os.path.join(path,\"dicom_dir/\"),\n","        preproc,\n","        True,\n","        aug]\n","\n","trainValData, testData = Images(*args).splitTrainTest(0.85)\n","\n","# Get architecture\n","net = VAE(model_params,1,1,True)\n","\n","# Get cross-validation folds\n","if model_params[\"K\"] > 1:\n","    kfold = KFold(n_splits=model_params[\"K\"], random_state=2)\n","    \n","    cont_fold = 1\n","    \n","    train_losses = []\n","    val_losses = []\n","    maes = []\n","    ssims = []\n","    psnrs = []\n","    \n","    for train_idx,val_idx in kfold.split(trainValData):\n","        \n","        # Get train and validation datasets and dataloaders\n","        #trainData,valData = splitTrainValData(trainValData,train_idx,val_idx)\n","        \n","        trainData,valData = trainValData.splitTrainTest((train_idx,val_idx))\n","\n","        loader_train = getDataLoader(trainData,model_params)\n","        loader_val = getDataLoader(valData,model_params)\n","\n","        # Training + validation\n","        print(\"\\nStart training network, fold {}...\\n\".format(cont_fold))\n","        \n","        train_loss,val_loss,mae,ssim,psnr = train.train(net,loader_train,\n","                                                       loader_val,model_params,\n","                                                       log,cont_fold)\n","        \n","        train_losses.append(train_loss)\n","        val_losses.append(val_loss)\n","        maes.append(mae)\n","        ssims.append(ssim)\n","        psnrs.append(psnr)\n","        \n","        cont_fold += 1\n","    \n","    train_losses = np.array(list(itertools.chain.from_iterable(train_losses))).astype(float)\n","    val_losses = np.array(list(itertools.chain.from_iterable(val_losses))).astype(float)\n","    maes = np.array(list(itertools.chain.from_iterable(maes))).astype(float)\n","    ssims = np.array(list(itertools.chain.from_iterable(ssims))).astype(float)\n","    psnrs = np.array(list(itertools.chain.from_iterable(psnrs))).astype(float)\n","    \n","    print(\"FINAL EVALUATION:\")\n","    print(\"Train loss: {}+-{}\".format(round(train_losses.mean(),4),round(train_losses.std(),4)))\n","    print(\"MAE: {}+-{}\".format(round(maes.mean(),4),round(maes.std(),4)))\n","    print(\"SSIM: {}+-{}\".format(round(ssims.mean(),4),round(ssims.std(),4)))\n","    print(\"PSNR: {}+-{}\".format(round(psnrs.mean(),4),round(psnrs.std(),4)))\n","    \n","    if os.path.exists(log):\n","        with open(log,\"a\") as f:\n","            f.write(\"\\nFINAL EVALUATION:\\n\")\n","            f.write(\"Train loss: {}+-{}\\n\".format(round(train_losses.mean(),4),round(train_losses.std(),4)))\n","            f.write(\"MAE: {}+-{}\\n\".format(round(maes.mean(),4),round(maes.std(),4)))\n","            f.write(\"SSIM: {}+-{}\\n\".format(round(ssims.mean(),4),round(ssims.std(),4)))\n","            f.write(\"PSNR: {}+-{}\\n\".format(round(psnrs.mean(),4),round(psnrs.std(),4)))\n","        \n","else:\n","    loader_train = getDataLoader(trainValData,model_params)\n","    \n","    # Training\n","    print(\"\\nStart training network...\\n\")\n","\n","    train_loss,out_model,optimizer,scheduler,loss = train.train(net,loader_train,None,\n","                                                    model_params,log)\n","    \n","    # Model saving\n","    state = {'iteration'  : model_params[\"epochs\"], \n","             'state_dict' : out_model.state_dict(),\n","             'optimizer'  : optimizer.state_dict(), \n","             'lr_sched'   : scheduler,\n","             'loss'       : loss}\n","\n","    filename = \"pretrainedVAE_epochs{}_lr{}_noCrossVal.tar\".format(model_params[\"epochs\"],\n","                                                                   model_params[\"lr\"])\n","    \n","    torch.save(state, os.path.join(log_folder,filename))\n","    \n","    \n","print(\"Processing done! Time ellapsed: {}h\".format(round((time.time()-init)/3600,2)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n","Start training network...\n","\n","Training: Fold: 0, Iteration: 0 // Loss distribution: 1.2434+-0.0\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-33847957e0f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     train_loss,out_model,optimizer,scheduler,loss = train.train(net,loader_train,None,\n\u001b[0;32m--> 129\u001b[0;31m                                                     model_params,log)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Model saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/AI_in_Healthcare_Hackaton/Scripts/Code_Andres/training_code/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, loader_train, loader_val, params, log, k)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m# one step of the optmizer (using the gradients from backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"4nwl-h6w6DEu"},"source":[""],"execution_count":null,"outputs":[]}]}